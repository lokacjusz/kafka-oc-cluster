kind: Template
apiVersion: v1
metadata:
  name: kafka-zk-persistent
  annotations:
    openshift.io/display-name: Kafka [+Zookeeper] (Persistent)
    description: Deploy a Kafka cluster, and an optional zookeeper, with persistent storage.
    iconClass: icon-database
    tags: messaging,kafka
labels:
  template: kafka-zk-persistent
  component: kafka
parameters:
- name: NAME
  description: Name.
  required: true
  value: kafka-zk-persistent
- name: KAFKA_VERSION
  description: Kafka Version (Scala and kafka version).
  required: true
  value: "2.13-2.5.0"
- name: SOURCE_IMAGE
  description: Container image source.
  value: kafka
  required: true
- name: REPLICAS
  description: Number of replicas.
  required: true
  value: "1"
- name: ZK_HEAP_OPTS
  description: Zookeeper JVM Heap options. Consider value of params RESOURCE_MEMORY_REQ, RESOURCE_MEMORY_LIMIT and KAFKA_HEAP_OPTS.
  required: true
  value: "-Xmx512M -Xms512M"
- name: KAFKA_HEAP_OPTS
  description: Kafka JVM Heap options. Consider value of params RESOURCE_MEMORY_REQ, RESOURCE_MEMORY_LIMIT and ZK_HEAP_OPTS.
  required: true
  value: "-Xmx512M -Xms512M"
- name: SERVER_NUM_PARTITIONS
  description: >
    The default number of log partitions per topic.
    More partitions allow greater
    parallelism for consumption, but this will also result in more files across
    the brokers.
  required: true
  value: "1"
- name: SERVER_DELETE_TOPIC_ENABLE
  description: >
    Topic deletion enabled.
    Switch to enable topic deletion or not, default value is 'true'
  value: "true"
- name: SERVER_LOG_RETENTION_HOURS
  description: >
    Log retention hours.
    The minimum age of a log file to be eligible for deletion.
  value: "2147483647"
- name: SERVER_ZOOKEEPER_CONNECT_TIMEOUT
  description: >
    The max time that the client waits to establish a connection to zookeeper (ms).
  value: "6000"
  required: true
- name: VOLUME_KAFKA_CAPACITY
  description: Kafka logs capacity.
  required: true
  value: "10Gi"
- name: VOLUME_ZK_DATA_CAPACITY
  description: Zookeeper data capacity
  required: true
  value: "1Gi"
- name: VOLUME_ZK_DATALOG_CAPACITY
  description: Zookeeper data log capacity
  required: true
  value: "1Gi"
- name: RESOURCE_MEMORY_REQ
  description: The memory resource request.
  value: "1Gi"
- name: RESOURCE_MEMORY_LIMIT
  description: The limits for memory resource.
  value: "1Gi"
- name: RESOURCE_CPU_REQ
  description: The CPU resource request.
  value: "1"
- name: RESOURCE_CPU_LIMIT
  description: The limits for CPU resource.
  value: "1"
- name: LP_INITIAL_DELAY
  description: >
    LivenessProbe initial delay in seconds.
  value: "30"

objects:
- apiVersion: v1
  kind: Service
  metadata:
    name: ${NAME}
    labels:
      app: ${NAME}
      component: kafka
    annotations:
      service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
  spec:
    ports:
    - port: 9092
      name: server
    - port: 2181
      name: zkclient
    - port: 2888
      name: zkserver
    - port: 3888
      name: zkleader
    clusterIP: None
    selector:
      app: ${NAME}
      component: kafka
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    name: ${NAME}
    labels:
      app: ${NAME}
      component: kafka
  spec:
    podManagementPolicy: "Parallel"
    serviceName: ${NAME}
    selector:
      matchLabels:
        app: ${NAME}
        component: kafka
    replicas: ${REPLICAS}
    template:
      metadata:
        labels:
          app: ${NAME}
          template: kafka-zk-persistent
          component: kafka
#        annotations:
#          # Use this annotation if you want allocate each pod on different node
#          # Note the number of nodes must be upper than REPLICAS parameter.
#          scheduler.alpha.kubernetes.io/affinity: >
#            {
#              "podAntiAffinity": {
#                "requiredDuringSchedulingIgnoredDuringExecution": [{
#                  "labelSelector": {
#                    "matchExpressions": [{
#                      "key": "app",
#                      "operator": "In",
#                      "values": ["${NAME}"]
#                    }]
#                  },
#                  "topologyKey": "kubernetes.io/hostname"
#                }]
#              }
#            }
      spec:
        containers:
        - name: ${NAME}
          imagePullPolicy: IfNotPresent
          image: ${SOURCE_IMAGE}:${KAFKA_VERSION}
          resources:
            requests:
              memory: ${RESOURCE_MEMORY_REQ}
              cpu: ${RESOURCE_CPU_REQ}
            limits:
              memory: ${RESOURCE_MEMORY_LIMIT}
              cpu: ${RESOURCE_CPU_LIMIT}
          ports:
          - containerPort: 9092
            name: server
          - containerPort: 2181
            name: zkclient
          - containerPort: 2888
            name: zkserver
          - containerPort: 3888
            name: zkleader
          env:
          - name : KAFKA_REPLICAS
            value: ${REPLICAS}
          - name:  KAFKA_ZK_LOCAL
            value: "true"
          - name : ZOO_HEAP_OPTS
            value: ${ZK_HEAP_OPTS}
          - name:  KAFKA_HEAP_OPTS
            value: ${KAFKA_HEAP_OPTS}
          - name:  SERVER_num_partitions
            value: ${SERVER_NUM_PARTITIONS}
          - name:  SERVER_delete_topic_enable
            value: ${SERVER_DELETE_TOPIC_ENABLE}
          - name:  SERVER_log_retention_hours
            value: ${SERVER_LOG_RETENTION_HOURS}
          - name:  SERVER_zookeeper_connect
            value: "localhost:2181"
          - name:  SERVER_log_dirs
            value: "/opt/kafka/data/logs"
          - name:  SERVER_zookeeper_connection_timeout_ms
            value: ${SERVER_ZOOKEEPER_CONNECT_TIMEOUT}
          # TODO: Resolve HostNotFound exception of zookeeper servers while kafka is starting up
          #readinessProbe:
          #  exec:
          #    command:
          #    - kafka_server_status.sh
          #  initialDelaySeconds: 15
          #  timeoutSeconds: 5
          livenessProbe:
            exec:
              command:
              - kafka_server_status.sh
            initialDelaySeconds: ${LP_INITIAL_DELAY}
            timeoutSeconds: 5
          securityContext:
            runAsUser: 1001
            fsGroup: 1001
          volumeMounts:
          - name: kafka-data
            mountPath: /opt/kafka/data
          - name: zk-data
            mountPath: /opt/kafka/zookeeper/data
          - name: zk-datalog
            mountPath: /opt/kafka/zookeeper/data-log
    volumeClaimTemplates:
    - metadata:
        name: kafka-data
        annotations:
          volume.alpha.kubernetes.io/storage-class: anything
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: ${VOLUME_KAFKA_CAPACITY}
    - metadata:
        name: zk-data
        annotations:
          volume.alpha.kubernetes.io/storage-class: anything
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: ${VOLUME_ZK_DATA_CAPACITY}
    - metadata:
        name: zk-datalog
        annotations:
          volume.alpha.kubernetes.io/storage-class: anything
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: ${VOLUME_ZK_DATALOG_CAPACITY}
